<!DOCTYPE html>
<html>

<head>
    <title>Voice Assistant (WebSocket Test)</title>
    <style>
        h2,
        .ch,
        .ct {
            color: white;
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background-color: black;
        }

        button {
            padding: 10px 20px;
            margin: 10px;
            font-size: 16px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }

        .start-btn {
            background-color: #4CAF50;
            color: white;
        }

        .stop-btn {
            background-color: #f44336;
            color: white;
        }

        .start-btn:disabled,
        .stop-btn:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }

        #response {
            color: white;
            border: grey 1px solid;
            padding: 15px;
            border-radius: 5px;
            min-height: 100px;
            margin-top: 20px;
            white-space: pre-wrap;
            word-wrap: break-word;
            font-family: inherit;
        }

        #transcript {
            color: #90EE90;
            border: #4CAF50 1px solid;
            padding: 15px;
            border-radius: 5px;
            min-height: 50px;
            margin-top: 20px;
            font-style: italic;
        }

        #status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
        }

        .status-connected {
            background-color: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status-disconnected {
            background-color: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status-recording {
            background-color: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }

        .status-processing {
            background-color: #cce5ff;
            color: #004085;
            border: 1px solid #b3d9ff;
        }

        .typing-indicator {
            color: #888;
            font-style: italic;
        }

        .typing-indicator::after {
            content: '...';
            animation: dots 1.5s infinite;
        }

        @keyframes dots {

            0%,
            20% {
                content: '';
            }

            40% {
                content: '.';
            }

            60% {
                content: '..';
            }

            80%,
            100% {
                content: '...';
            }
        }

        .error {
            color: #ff6b6b;
            background-color: #2d1b1b;
            padding: 10px;
            border-radius: 5px;
            margin-top: 10px;
        }

        .conversation-history {
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid #333;
            padding: 10px;
            margin-top: 20px;
            background-color: #111;
        }

        .conversation-item {
            margin: 10px 0;
            padding: 8px;
            border-radius: 5px;
        }

        .user-message {
            background-color: #1a3d1a;
            color: #90EE90;
            border-left: 3px solid #4CAF50;
        }

        .assistant-message {
            background-color: #1a1a3d;
            color: #90c5f7;
            border-left: 3px solid #4a90e2;
        }
    </style>
</head>

<body>
    <h2>Agent Tests</h2>

    <div id="status" class="status-disconnected">
        Status: Disconnected
    </div>

    <button id="startBtn" class="start-btn" onclick="startRecording()">üé§ Start Recording</button>
    <button id="stopBtn" class="stop-btn" onclick="stopRecording()" disabled>üõë Stop</button>
    <button id="clearBtn" class="start-btn" onclick="clearConversation()">üóëÔ∏è Clear</button>

    <p><strong class="ct">Current Transcript:</strong></p>
    <div id="transcript">Listening...</div>

    <p><strong class="ch">Assistant Response:</strong></p>
    <div id="response">No response yet</div>

    <p><strong class="ch">Conversation History:</strong></p>
    <div id="conversationHistory" class="conversation-history"></div>

    <script>
        let socket;
        let audioContext;
        let mediaStreamSource;
        let processor;
        let isRecording = false;
        let currentResponse = '';
        let conversationHistory = [];
        let isProcessing = false;

        function updateStatus(message, className) {
            const statusEl = document.getElementById('status');
            statusEl.textContent = `Status: ${message}`;
            statusEl.className = className;
        }

        function updateButtons(recording) {
            document.getElementById('startBtn').disabled = recording;
            document.getElementById('stopBtn').disabled = !recording;
        }

        function updateTranscript(text) {
            document.getElementById('transcript').textContent = text || 'Listening...';
        }

        function updateResponse(text, isComplete = false) {
            const responseEl = document.getElementById('response');
            if (isComplete) {
                responseEl.textContent = text;
                responseEl.classList.remove('typing-indicator');
            } else {
                responseEl.textContent = text;
                if (!isComplete && isProcessing) {
                    responseEl.classList.add('typing-indicator');
                }
            }
        }

        function showError(message) {
            const responseEl = document.getElementById('response');
            responseEl.innerHTML = `<div class="error">Error: ${message}</div>`;
            responseEl.classList.remove('typing-indicator');
            isProcessing = false;
        }

        function addToConversationHistory(transcript, response) {
            conversationHistory.push({ transcript, response, timestamp: new Date() });
            renderConversationHistory();
        }

        function renderConversationHistory() {
            const historyEl = document.getElementById('conversationHistory');
            historyEl.innerHTML = '';

            conversationHistory.forEach((item, index) => {
                const userDiv = document.createElement('div');
                userDiv.className = 'conversation-item user-message';
                userDiv.innerHTML = `<strong>You:</strong> ${item.transcript}`;

                const assistantDiv = document.createElement('div');
                assistantDiv.className = 'conversation-item assistant-message';
                assistantDiv.innerHTML = `<strong>Assistant:</strong> ${item.response}`;

                historyEl.appendChild(userDiv);
                historyEl.appendChild(assistantDiv);
            });


            historyEl.scrollTop = historyEl.scrollHeight;
        }

        function clearConversation() {
            conversationHistory = [];
            renderConversationHistory();
            updateResponse('No response yet');
            updateTranscript('Listening...');
        }


        function float32ToInt16(float32Array) {
            const int16Array = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {

                const clampedValue = Math.max(-1, Math.min(1, float32Array[i]));
                int16Array[i] = clampedValue * 0x7FFF;
            }
            return int16Array;
        }


        function resampleTo16kHz(audioBuffer, sourceSampleRate) {
            if (sourceSampleRate === 16000) {
                return audioBuffer;
            }

            const ratio = sourceSampleRate / 16000;
            const newLength = Math.round(audioBuffer.length / ratio);
            const result = new Float32Array(newLength);

            for (let i = 0; i < newLength; i++) {
                const sourceIndex = i * ratio;
                const index = Math.floor(sourceIndex);
                const fraction = sourceIndex - index;

                if (index + 1 < audioBuffer.length) {

                    result[i] = audioBuffer[index] * (1 - fraction) + audioBuffer[index + 1] * fraction;
                } else {
                    result[i] = audioBuffer[index];
                }
            }

            return result;
        }

        async function startRecording() {
            try {
                updateStatus("Requesting microphone permission...", "status-recording");


                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });


                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });

                updateStatus("Connecting to server...", "status-recording");


                socket = new WebSocket("ws://localhost:8000/ws");

                socket.onopen = () => {
                    console.log("WebSocket connected");
                    updateStatus("Connected - Recording...", "status-connected");
                    socket.send('{"authToken" : "this is auth token","projects" : ["p1"], "tasks" : [{"name" : "this is task"}]}')
                    isRecording = true;
                    updateButtons(true);
                    updateTranscript('Listening...');


                    mediaStreamSource = audioContext.createMediaStreamSource(stream);


                    processor = audioContext.createScriptProcessor(4096, 1, 1);

                    processor.onaudioprocess = (event) => {
                        if (!isRecording || socket.readyState !== WebSocket.OPEN) {
                            return;
                        }

                        const inputBuffer = event.inputBuffer;
                        const inputData = inputBuffer.getChannelData(0);


                        const resampledData = resampleTo16kHz(inputData, inputBuffer.sampleRate);


                        const pcmData = float32ToInt16(resampledData);


                        if (socket.readyState === WebSocket.OPEN) {
                            socket.send(pcmData.buffer);
                        }
                    };


                    mediaStreamSource.connect(processor);
                    processor.connect(audioContext.destination);
                };

                socket.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        console.log("Received message:", data);

                        switch (data.type) {
                            case 'start':
                                console.log("Processing started for:", data.transcript);
                                updateTranscript(data.transcript);
                                updateStatus("Processing response...", "status-processing");
                                currentResponse = '';
                                isProcessing = true;
                                updateResponse('', false);
                                break;

                            case 'chunk':
                                console.log("Received chunk:", data.text);
                                currentResponse += data.text;
                                updateResponse(currentResponse, false);
                                break;

                            case 'end':
                                console.log("Response completed");
                                updateResponse(currentResponse, true);
                                updateStatus("Connected - Recording...", "status-connected");
                                isProcessing = false;


                                const transcript = document.getElementById('transcript').textContent;
                                if (transcript && transcript !== 'Listening...' && currentResponse) {
                                    addToConversationHistory(transcript, currentResponse);
                                }


                                updateTranscript('Listening...');
                                break;

                            case 'error':
                                console.error("Server error:", data.text);
                                showError(data.text);
                                updateStatus("Connected - Recording...", "status-connected");
                                updateTranscript('Listening...');
                                break;

                            default:

                                console.log("Received legacy response:", event.data);
                                updateResponse(event.data, true);
                                break;
                        }
                    } catch (error) {

                        console.log("Received non-JSON response:", event.data);
                        updateResponse(event.data, true);
                    }
                };

                socket.onerror = (error) => {
                    console.error("WebSocket error:", error);
                    updateStatus("Connection error", "status-disconnected");
                    showError("Connection error occurred");
                    stopRecording();
                };

                socket.onclose = () => {
                    console.log("WebSocket closed");
                    updateStatus("Disconnected", "status-disconnected");
                    stopRecording();
                };

            } catch (error) {
                console.error("Error starting recording:", error);
                updateStatus(`Error: ${error.message}`, "status-disconnected");
                showError(`Error starting recording: ${error.message}`);
            }
        }

        function stopRecording() {
            isRecording = false;
            isProcessing = false;
            updateButtons(false);


            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (mediaStreamSource) {
                mediaStreamSource.disconnect();
                mediaStreamSource = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }


            if (socket) {
                socket.close();
                socket = null;
            }

            updateStatus("Disconnected", "status-disconnected");
            updateTranscript('Listening...');
            console.log("Recording stopped");
        }


        window.addEventListener('beforeunload', () => {
            stopRecording();
        });


        updateButtons(false);
        renderConversationHistory();
    </script>
</body>

</html>